{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import requests, bs4\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db14 = pd.read_csv('WNBA14.csv')\n",
    "db15 = pd.read_csv('WNBA15.csv')\n",
    "db16 = pd.read_csv('WNBA16.csv')\n",
    "db17 = pd.read_csv('WNBA17.csv')\n",
    "db18 = pd.read_csv('WNBA18.csv')\n",
    "db = pd.concat([db14, db15, db16, db17]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check results using 2015-2017 data on 2018 games "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols =  ['Result', 'Location','Rolling4TSP','Rolling4TOV','Rolling4ORB','Rolling4FTR','Rolling4Poss','Opp R4Poss','Opp R4TSP','Opp R4TOV','Opp R4ORB','Opp R4FTR', 'Rolling4DEff', 'Opp R4DEff', 'Rolling4OEff','Opp R4OEff']\n",
    "featureCols = ['Location','Rolling4TSP','Rolling4TOV','Rolling4ORB','Rolling4FTR','Rolling4Poss','Opp R4Poss','Opp R4TSP','Opp R4TOV','Opp R4ORB','Opp R4FTR', 'Rolling4DEff', 'Opp R4DEff', 'Rolling4OEff','Opp R4OEff']\n",
    "target = ['Result']\n",
    "\n",
    "db = db[cols].dropna()\n",
    "\n",
    "X = db[featureCols]\n",
    "y = np.array(db[target]).flatten()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All picks (R9): 0.6203703703703703\n",
      "All picks (R9) matrix:\n",
      " [[130 100]\n",
      " [ 64 138]]\n",
      " \n",
      "0.6241928540680156\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(n_estimators=100, learning_rate=0.1).fit(x_train, y_train)\n",
    "pred = ada.predict(x_test)\n",
    "print('All picks (R9):',ada.score(x_test, y_test))\n",
    "print('All picks (R9) matrix:\\n',confusion_matrix(y_test, pred))\n",
    "print(' ')\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(roc_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2018 test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs2018 = db18[(db18['Odds'] > 0)].dropna().reset_index()\n",
    "Ydogs2018 = db18[(db18['Odds'] > 0)].dropna()['Result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dog data\n",
      "\n",
      "Dog picks: 0.6488095238095238\n",
      "Dog picks matrix:\n",
      " [[84 28]\n",
      " [31 25]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Using dog data\\n\")\n",
    "\n",
    "pred1 = ada.predict(dogs2018[featureCols])\n",
    "print('Dog picks:',ada.score(dogs2018[featureCols], Ydogs2018))\n",
    "print('Dog picks matrix:\\n',confusion_matrix(Ydogs2018, pred1))\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odds = []\n",
    "for i, n in enumerate(pred1):\n",
    "    if n == 1:\n",
    "        odds.append(dogs2018['Odds'][i])\n",
    "import statistics\n",
    "statistics.mean(odds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is a realistic expectation of what a running database may look like. I added half the season's worth of 2019 onto the 2018 db, and dropped the first half of 2018. The model now looks at the second half of 2018 and the first half of 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature3Cols = ['Location','Rolling3EFG','Rolling3TOV','Rolling3ORB','Rolling3FTR','Rolling3Pace','Opp R3Pace','Opp R3EFG','Opp R3TOV','Opp R3ORB','Opp R3FTR']\n",
    "#feature9Cols = ['Location','Rolling9EFG','Rolling9TOV','Rolling9ORB','Rolling9FTR','Rolling9Pace','Opp R9Pace','Opp R9EFG','Opp R9TOV','Opp R9ORB','Opp R9FTR']\n",
    "\n",
    "target = ['Result']\n",
    "X3 = db.dropna()[feature3Cols]\n",
    "X9 = db.dropna()[feature9Cols]\n",
    "y = np.array(db.dropna()[target]).flatten()\n",
    "\n",
    "x9_train, x9_test, y9_train, y9_test = train_test_split(X9, y, test_size=0.3)\n",
    "x3_train, x3_test, y3_train, y3_test = train_test_split(X3, y, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All picks (R9): 0.6445966514459666\n",
      "All picks (R9) matrix:\n",
      " [[419 239]\n",
      " [228 428]]\n",
      "0.6446085699458818\n",
      " \n",
      "All picks (R3): 0.6210045662100456\n",
      "All picks (R3) matrix:\n",
      " [[412 223]\n",
      " [275 404]]\n",
      "0.6219057669337724\n",
      " \n"
     ]
    }
   ],
   "source": [
    "ada9 = AdaBoostClassifier(n_estimators=50, learning_rate=0.1).fit(x9_train, y9_train)\n",
    "pred = ada9.predict(x9_test)\n",
    "print('All picks (R9):',ada9.score(x9_test, y9_test))\n",
    "print('All picks (R9) matrix:\\n',confusion_matrix(y9_test, pred))\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y9_test, pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(roc_auc)\n",
    "print(' ')\n",
    "\n",
    "ada3 = AdaBoostClassifier(n_estimators=50, learning_rate=0.1).fit(x3_train, y3_train)\n",
    "pred = ada3.predict(x3_test)\n",
    "print('All picks (R3):',ada3.score(x3_test, y3_test))\n",
    "print('All picks (R3) matrix:\\n',confusion_matrix(y3_test, pred))\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y3_test, pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(roc_auc)\n",
    "print(' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ahelgeso/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/ahelgeso/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "dogs2019 = db19[int(len(db19)/2):][db19['Line'] > 0].dropna().reset_index()\n",
    "Ydogs2019 = db19[int(len(db19)/2):][db19['Line'] > 0].dropna()['Result']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is now predicting all underdog games for last half of season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dog data[rolling 9 averages]: \n",
      "\n",
      "Using 9 game standard predictor: \n",
      "Dog picks: 0.6115702479338843\n",
      "Dog picks matrix:\n",
      " [[299 113]\n",
      " [122  71]]\n",
      "\n",
      "Using 3 game standard predictor: \n",
      "Dog picks: 0.6413223140495867\n",
      "Dog picks matrix:\n",
      " [[324  88]\n",
      " [129  64]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Using dog data[rolling 9 averages]: \\n\")\n",
    "\n",
    "print(\"Using 9 game standard predictor: \")\n",
    "pred1 = ada9.predict(dogs2019[feature9Cols])\n",
    "print('Dog picks:',ada9.score(dogs2019[feature9Cols], Ydogs2019))\n",
    "print('Dog picks matrix:\\n',confusion_matrix(Ydogs2019, pred1))\n",
    "print('')\n",
    "\n",
    "print(\"Using 3 game standard predictor: \")\n",
    "pred2 = ada3.predict(dogs2019[feature9Cols])\n",
    "print('Dog picks:',ada3.score(dogs2019[feature9Cols], Ydogs2019))\n",
    "print('Dog picks matrix:\\n',confusion_matrix(Ydogs2019, pred2))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average odds: 164\n",
      "Median odds: 156.5\n",
      "Average odds: 174\n",
      "Median odds: 160.0\n"
     ]
    }
   ],
   "source": [
    "odds = []\n",
    "for i, n in enumerate(pred1):\n",
    "    if n == 1:\n",
    "        odds.append(dogs2019['Odds'][i])\n",
    "\n",
    "print(\"Average odds:\", statistics.mean(odds))\n",
    "print(\"Median odds:\", statistics.median(odds))\n",
    "\n",
    "odds = []\n",
    "for i, n in enumerate(pred2):\n",
    "    if n == 1:\n",
    "        odds.append(dogs2019['Odds'][i])\n",
    "\n",
    "print(\"Average odds:\", statistics.mean(odds))\n",
    "print(\"Median odds:\", statistics.median(odds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using rolling 3 averages: \n",
      "\n",
      "Using 9 game standard predictor: \n",
      "Dog picks: 0.6396694214876033\n",
      "Dog picks matrix:\n",
      " [[305 107]\n",
      " [111  82]]\n",
      "\n",
      "Using 3 game standard predictor: \n",
      "Dog picks: 0.6644628099173554\n",
      "Dog picks matrix:\n",
      " [[323  89]\n",
      " [114  79]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Using rolling 3 averages: \\n\")\n",
    "\n",
    "print(\"Using 9 game standard predictor: \")\n",
    "pred1 = ada9.predict(dogs2019[feature3Cols])\n",
    "print('Dog picks:',ada9.score(dogs2019[feature3Cols], Ydogs2019))\n",
    "print('Dog picks matrix:\\n',confusion_matrix(Ydogs2019, pred1))\n",
    "print('')\n",
    "\n",
    "print(\"Using 3 game standard predictor: \")\n",
    "pred2 = ada3.predict(dogs2019[feature3Cols])\n",
    "print('Dog picks:',ada3.score(dogs2019[feature3Cols], Ydogs2019))\n",
    "print('Dog picks matrix:\\n',confusion_matrix(Ydogs2019, pred2))\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average odds: 191\n",
      "Median odds: 165\n",
      "Average odds: 181\n",
      "Median odds: 160.0\n"
     ]
    }
   ],
   "source": [
    "odds = []\n",
    "for i, n in enumerate(pred1):\n",
    "    if n == 1:\n",
    "        odds.append(dogs2019['Odds'][i])\n",
    "\n",
    "print(\"Average odds:\", statistics.mean(odds))\n",
    "print(\"Median odds:\", statistics.median(odds))\n",
    "\n",
    "odds = []\n",
    "for i, n in enumerate(pred2):\n",
    "    if n == 1:\n",
    "        odds.append(dogs2019['Odds'][i])\n",
    "\n",
    "print(\"Average odds:\", statistics.mean(odds))\n",
    "print(\"Median odds:\", statistics.median(odds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model drops 2018 data when adding first half of 2019.\n",
    "\n",
    "The 9-game predictor goes 85-141 using 3-game average data, with average odds of 229.\n",
    "\n",
    "The 3-game predictor goes 70-116 using 3-game average data, with average odds of 220."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_filename = \"ADA9model.pkl\"  \n",
    "with open(pkl_filename, 'wb') as file:  \n",
    "    pickle.dump(ada9, file)\n",
    "    \n",
    "pkl_filename = \"ADA3model.pkl\"  \n",
    "with open(pkl_filename, 'wb') as file:  \n",
    "    pickle.dump(ada3, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ahelgeso/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 0.20.3 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/ahelgeso/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator GradientBoostingClassifier from version 0.20.3 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "model3 = pickle.load(open('GBC3Model.pkl', 'rb'))\n",
    "model9 = pickle.load(open('GBC9Model.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dog data[rolling 9 averages]: \n",
      "\n",
      "Using 9 game standard predictor: \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model9' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-5478554b0f1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Using 9 game standard predictor: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpred1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel9\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdogs2019\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature9Cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Dog picks:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel9\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdogs2019\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature9Cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYdogs2019\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Dog picks matrix:\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYdogs2019\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model9' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Using dog data[rolling 9 averages]: \\n\")\n",
    "\n",
    "print(\"Using 9 game standard predictor: \")\n",
    "pred1 = model9.predict(dogs2019[feature9Cols])\n",
    "print('Dog picks:',model9.score(dogs2019[feature9Cols], Ydogs2019))\n",
    "print('Dog picks matrix:\\n',confusion_matrix(Ydogs2019, pred1))\n",
    "print('')\n",
    "\n",
    "print(\"Using 3 game standard predictor: \")\n",
    "pred2 = model3.predict(dogs2019[feature9Cols])\n",
    "print('Dog picks:',model3.score(dogs2019[feature9Cols], Ydogs2019))\n",
    "print('Dog picks matrix:\\n',confusion_matrix(Ydogs2019, pred2))\n",
    "print('')\n",
    "\n",
    "odds = []\n",
    "for i, n in enumerate(pred1):\n",
    "    if n == 1:\n",
    "        odds.append(dogs2019['Odds'][i])\n",
    "\n",
    "print(\"Average odds:\", statistics.mean(odds))\n",
    "print(\"Median odds:\", statistics.median(odds))\n",
    "\n",
    "odds = []\n",
    "for i, n in enumerate(pred2):\n",
    "    if n == 1:\n",
    "        odds.append(dogs2019['Odds'][i])\n",
    "\n",
    "print(\"Average odds:\", statistics.mean(odds))\n",
    "print(\"Median odds:\", statistics.median(odds))\n",
    "\n",
    "\n",
    "print(\"\\nUsing rolling 3 averages: \\n\")\n",
    "\n",
    "print(\"Using 9 game standard predictor: \")\n",
    "pred1 = model9.predict(dogs2019[feature3Cols])\n",
    "print('Dog picks:',model9.score(dogs2019[feature3Cols], Ydogs2019))\n",
    "print('Dog picks matrix:\\n',confusion_matrix(Ydogs2019, pred1))\n",
    "print('')\n",
    "\n",
    "print(\"Using 3 game standard predictor: \")\n",
    "pred2 = model3.predict(dogs2019[feature3Cols])\n",
    "print('Dog picks:',model3.score(dogs2019[feature3Cols], Ydogs2019))\n",
    "print('Dog picks matrix:\\n',confusion_matrix(Ydogs2019, pred2))\n",
    "print('')\n",
    "\n",
    "odds = []\n",
    "for i, n in enumerate(pred1):\n",
    "    if n == 1:\n",
    "        odds.append(dogs2019['Odds'][i])\n",
    "\n",
    "print(\"Average odds:\", statistics.mean(odds))\n",
    "print(\"Median odds:\", statistics.median(odds))\n",
    "\n",
    "odds = []\n",
    "for i, n in enumerate(pred2):\n",
    "    if n == 1:\n",
    "        odds.append(dogs2019['Odds'][i])\n",
    "\n",
    "print(\"Average odds:\", statistics.mean(odds))\n",
    "print(\"Median odds:\", statistics.median(odds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
