{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import requests, bs4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import os\n",
    "from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order to run these:\n",
    "##### To get games up to this point:\n",
    "db = wnba_update(2019) <br>\n",
    "db = db_format(db)\n",
    "\n",
    "### To get today's scheduled games: \n",
    "today_games = todays_games(date)\n",
    "\n",
    "### Predictions:\n",
    "predict_db(db, today_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wnba_scrape(team, year):\n",
    "\n",
    "    # Date format = YYYYMMDD\n",
    "    # 1. Create schedule from basketball-reference\n",
    "    # 2. Get basic stats for just the teams\n",
    "    # 3. Match opponent stats using indexes (Different function)\n",
    "    # 4. Comupte rolling averages (different function?)\n",
    "    # 5. Get betting lines (different function)\n",
    "\n",
    "    def date_formatter(date):\n",
    "\n",
    "        if len(str(date.month)) != 2:\n",
    "            month = '0'+ str(date.month)\n",
    "        else:\n",
    "            month = str(date.month)\n",
    "\n",
    "        if len(str(date.day)) != 2:\n",
    "            day = '0' + str(date.day)\n",
    "        else:\n",
    "            day = str(date.day)\n",
    "\n",
    "        newdate = str(date.year) + month + day\n",
    "        return newdate\n",
    "\n",
    "    team_abbrevs = {\n",
    "    'Atlanta Dream': 'ATL',\n",
    "    'Washington Mystics': 'WAS',\n",
    "    'Connecticut Sun': 'CON',\n",
    "    'Chicago Sky': 'CHI',\n",
    "    'New York Liberty': 'NYL',\n",
    "    'Indiana Fever': 'IND',\n",
    "    'Seattle Storm': 'SEA',\n",
    "    'Phoenix Mercury': 'PHO',\n",
    "    'Los Angeles Sparks':'LAS',\n",
    "    'Minnesota Lynx': 'MIN',\n",
    "    'Dallas Wings': 'DAL',\n",
    "    'Las Vegas Aces': 'LVA'\n",
    "    }\n",
    "\n",
    "    url = f'https://www.basketball-reference.com/wnba/schedules/{team}/{year}.html'\n",
    "    res = requests.get(url, 'html.parser')\n",
    "    res.raise_for_status()\n",
    "    soup = bs4.BeautifulSoup(res.text, 'lxml')\n",
    "    reg_season = soup.find('table',{'id':'teams_games'})\n",
    "\n",
    "    oppts = reg_season.find_all(attrs = {'data-stat':'opp_name'})\n",
    "    opps = [entry.get_text() for entry in oppts if entry.get_text() != \"Opponent\"]\n",
    "    opp_abbrev = [team_abbrevs[opp] for opp in opps]\n",
    "\n",
    "    datesoup = reg_season.find_all(attrs = {'data-stat':'date_game'})\n",
    "    dates = [entry.get_text() for entry in datesoup if entry.get_text() != 'Date']\n",
    "\n",
    "    souppoints = reg_season.find_all(attrs = {'data-stat':'pts'})\n",
    "    soupopp = reg_season.find_all(attrs = {'data-stat':'opp_pts'})\n",
    "\n",
    "    teampoints = [entry.get_text() for entry in souppoints if not entry.get_text().startswith('T')]\n",
    "    opppoints = [entry.get_text() for entry in soupopp if not entry.get_text().startswith('O')]\n",
    "\n",
    "    teampoints = list(map(lambda x: int(x), teampoints))\n",
    "    opppoints = list(map(lambda x: int(x), opppoints))\n",
    "\n",
    "    gamelocs = reg_season.find_all(attrs = {'data-stat':'game_location'})\n",
    "    locs = [entry.get_text() for entry in gamelocs if entry.get_text() == '' or entry.get_text() == '@']\n",
    "    loc = list(map(lambda x: 1 if x =='' else 0, locs))\n",
    "\n",
    "    result = [1 if (teampoints[i] - opppoints[i] > 0) else 0 for i in range(len(teampoints)) ]    \n",
    "\n",
    "    links = reg_season.find_all(attrs = {'data-stat':'date_game'})\n",
    "    urls = []\n",
    "    for i in links:\n",
    "        if i.find('a'):\n",
    "            urls.append(i.find('a').attrs['href'])\n",
    "\n",
    "    FG = []\n",
    "    FGA = []\n",
    "    threeP = []\n",
    "    threePA = []\n",
    "    FT = []\n",
    "    FTA = []\n",
    "    ORB = []\n",
    "    TRB = []\n",
    "    AST = []\n",
    "    STL = []\n",
    "    BLK = []\n",
    "    TOV = []\n",
    "    PF = []\n",
    "    PTS = []\n",
    "\n",
    "    for i, url in enumerate(urls):\n",
    "        url = f'https://www.basketball-reference.com{url}'\n",
    "        res = requests.get(url)\n",
    "        res.raise_for_status()\n",
    "        soup = bs4.BeautifulSoup(re.sub(\"<!--|-->\", \"\", res.text), 'lxml')\n",
    "        opp = opp_abbrev[i].lower()\n",
    "        gameteam = soup.find('div',{'id':f'div_box-score-{team.lower()}'})\n",
    "        gameteam = pd.read_html(str(gameteam.find('table')), flavor='bs4')[0]\n",
    "        gameteam = gameteam.dropna()\n",
    "\n",
    "        FG.append(gameteam.iloc[-1]['FG'])\n",
    "        FGA.append(gameteam.iloc[-1]['FGA'])\n",
    "        threeP.append(gameteam.iloc[-1]['3P'])\n",
    "        threePA.append(gameteam.iloc[-1]['3PA'])\n",
    "        FT.append(gameteam.iloc[-1]['FT'])\n",
    "        FTA.append(gameteam.iloc[-1]['FTA'])\n",
    "        ORB.append(gameteam.iloc[-1]['ORB'])\n",
    "        TRB.append(gameteam.iloc[-1]['TRB'])\n",
    "        AST.append(gameteam.iloc[-1]['AST'])\n",
    "        STL.append(gameteam.iloc[-1]['STL'])\n",
    "        BLK.append(gameteam.iloc[-1]['BLK'])\n",
    "        TOV.append(gameteam.iloc[-1]['TOV'])\n",
    "        PF.append(gameteam.iloc[-1]['PF'])\n",
    "        PTS.append(gameteam.iloc[-1]['PTS'])\n",
    "\n",
    "    data = {\"Team\": [team] *len(dates), \"Opp\":opp_abbrev, \"Game Num\":list(range(1, len(dates)+1)), \"Date\":dates,\n",
    "       \"Location\": loc, \"FG\":FG, 'FGA':FGA, '3P':threeP, '3PA':threePA, 'FT':FT,\n",
    "       'FTA':FTA, 'ORB':ORB, 'TRB':TRB, 'AST':AST, 'STL':STL,'BLK':BLK,\n",
    "       'TOV':TOV, 'PF':PF, 'PTS':PTS}\n",
    "\n",
    "    db = pd.DataFrame(data)\n",
    "\n",
    "    db['Date'] = pd.to_datetime(db['Date'])\n",
    "    db['Date'] = db['Date'].apply(date_formatter)\n",
    "\n",
    "    return db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wnba_update(year):\n",
    "\n",
    "    def line_scrape(dates):\n",
    "\n",
    "        # Date format [YYYMMDD]\n",
    "\n",
    "        bet_abbrevs = {\n",
    "            'Atlanta Dream': 'ATL',\n",
    "            'Washington Mystics': 'WAS',\n",
    "            'Connecticut Sun': 'CON',\n",
    "            'Chicago Sky': 'CHI',\n",
    "            'New York Liberty': 'NYL',\n",
    "            'Indiana Fever': 'IND',\n",
    "            'Seattle Storm': 'SEA',\n",
    "            'Phoenix Mercury': 'PHO',\n",
    "            'L.A. Sparks':'LAS',\n",
    "            'Minnesota Lynx': 'MIN',\n",
    "            'Dallas Wings': 'DAL',\n",
    "            'Las Vegas Aces': 'LVA'\n",
    "        }\n",
    "\n",
    "        scraped_dates = []\n",
    "        moneydb = pd.DataFrame()\n",
    "\n",
    "        for date in dates:\n",
    "\n",
    "            if date not in scraped_dates:\n",
    "                #print(\"Date: \", date)\n",
    "                url = f'https://www.sportsbookreview.com/betting-odds/wnba-basketball/money-line/?date={date}'\n",
    "                res = requests.get(url, 'html.parser')\n",
    "                res.raise_for_status()\n",
    "                soup = bs4.BeautifulSoup(res.text, 'lxml')\n",
    "                linesoup = soup.find('div', {'id':'bettingOddsGridContainer'})\n",
    "                test_teams = linesoup.find_all('span', {'class':'_3O1Gx'})\n",
    "                teams = [bet_abbrevs[team.get_text()] for team in test_teams]\n",
    "                test_lines = linesoup.find_all('span', {'class':'opener'})\n",
    "                lines = [line.get_text() for line in test_lines if line.get_text().startswith('-') and len(line.get_text()) > 1 or line.get_text().startswith('+') and len(line.get_text()) > 1]\n",
    "                #print(\"teams:\",len(teams),\"lines\",len(lines))\n",
    "\n",
    "                if len(teams) != len(lines):\n",
    "                    pass\n",
    "                else:\n",
    "                    moneylines = {'Team':teams, 'ML Odds': lines, 'Date':[date]*len(teams)}\n",
    "\n",
    "                    MLdb = pd.DataFrame.from_dict(moneylines)\n",
    "                    moneydb = pd.concat([moneydb, MLdb])\n",
    "\n",
    "                scraped_dates.append(date)\n",
    "        return moneydb.reset_index(drop = True)\n",
    "        \n",
    "    team_abbrevs18 = {\n",
    "    'Atlanta Dream': 'ATL',\n",
    "    'Washington Mystics': 'WAS',\n",
    "    'Connecticut Sun': 'CON',\n",
    "    'Chicago Sky': 'CHI',\n",
    "    'New York Liberty': 'NYL',\n",
    "    'Indiana Fever': 'IND',\n",
    "    'Seattle Storm': 'SEA',\n",
    "    'Phoenix Mercury': 'PHO',\n",
    "    'Los Angeles Sparks':'LAS',\n",
    "    'Minnesota Lynx': 'MIN',\n",
    "    'Dallas Wings': 'DAL',\n",
    "    'Las Vegas Aces': 'LVA'\n",
    "    }\n",
    "    \n",
    "    \n",
    "    db = pd.DataFrame()\n",
    "    \n",
    "    for team in list(team_abbrevs18.values()):\n",
    "        print(team)\n",
    "        db_running = wnba_scrape(team,year)\n",
    "        db = pd.concat([db, db_running])\n",
    "    \n",
    "    db = db.reset_index(drop = True)\n",
    "    \n",
    "    moneydb = line_scrape(list(db['Date'].unique()))\n",
    "    \n",
    "    db['Odds'] = np.zeros(len(db['Team']))\n",
    "    \n",
    "    for i, date in enumerate(db['Date']):\n",
    "    \n",
    "        if date in list(moneydb['Date']):\n",
    "\n",
    "            db['Odds'][i] = moneydb[(moneydb['Date'] == date) & (moneydb['Team'] == db['Team'][i])]['ML Odds']\n",
    "            #print(\"Team:\", db['Team'][i], \"Odds:\", moneydb[(moneydb['Date'] == date) & (moneydb['Team'] == db['Team'][i])]['ML Odds'])\n",
    "\n",
    "        else:\n",
    "            db['Odds'][i] = np.nan\n",
    "    \n",
    "    return db\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_format(db):\n",
    "    \n",
    "    def rolling_avgs(db):\n",
    "        TSP4DB = pd.DataFrame()\n",
    "        rollingTSP = []\n",
    "        for team in db['Team'].unique():\n",
    "            teamRollingTSP = db[db['Team'] == team]['TS%'].rolling(4).mean()\n",
    "            rollingTSP.append(teamRollingTSP)\n",
    "            TSP = {\"Rolling4TSP\":teamRollingTSP}\n",
    "            TSP4df = pd.DataFrame.from_dict(TSP)\n",
    "            TSP4DB = pd.concat([TSP4DB, TSP4df])\n",
    "\n",
    "        TOV4DB = pd.DataFrame()\n",
    "        rollingTOV = []\n",
    "        for team in db['Team'].unique():\n",
    "            teamRollingTOV = db[db['Team'] == team]['TOV%'].rolling(4).mean()\n",
    "            rollingTOV.append(teamRollingTOV)\n",
    "            TOV = {\"Rolling4TOV\":teamRollingTOV}\n",
    "            TOV4df = pd.DataFrame.from_dict(TOV)\n",
    "            TOV4DB = pd.concat([TOV4DB, TOV4df])\n",
    "\n",
    "        ORB4DB = pd.DataFrame()\n",
    "        rollingORB = []\n",
    "        for team in db['Team'].unique():\n",
    "            teamRollingORB = db[db['Team'] == team]['ORB%'].rolling(4).mean()\n",
    "            rollingORB.append(teamRollingORB)\n",
    "            ORB = {\"Rolling4ORB\":teamRollingORB}\n",
    "            ORB4df = pd.DataFrame.from_dict(ORB)\n",
    "            ORB4DB = pd.concat([ORB4DB, ORB4df])\n",
    "\n",
    "        FTR4DB = pd.DataFrame()\n",
    "        rollingFTR = []\n",
    "        for team in db['Team'].unique():\n",
    "            teamRollingFTR = db[db['Team'] == team]['FTR'].rolling(4).mean()\n",
    "            rollingFTR.append(teamRollingFTR)\n",
    "            FTR = {\"Rolling4FTR\":teamRollingFTR}\n",
    "            FTR4df = pd.DataFrame.from_dict(FTR)\n",
    "            FTR4DB = pd.concat([FTR4DB, FTR4df])\n",
    "\n",
    "        Poss4DB = pd.DataFrame()\n",
    "        rollingPoss = []\n",
    "        for team in db['Team'].unique():\n",
    "            teamRollingPoss = db[db['Team'] == team]['Poss'].rolling(4).mean()\n",
    "            rollingPoss.append(teamRollingPoss)\n",
    "            POSS = {\"Rolling4Poss\":teamRollingPoss}\n",
    "            PACE4df = pd.DataFrame.from_dict(POSS)\n",
    "            Poss4DB = pd.concat([Poss4DB, PACE4df])\n",
    "\n",
    "        OEff4DB = pd.DataFrame()\n",
    "        rollingOEff = []\n",
    "        for team in db['Team'].unique():\n",
    "            teamRollingOEff = db[db['Team'] == team]['OEff'].rolling(4).mean()\n",
    "            rollingOEff.append(teamRollingOEff)\n",
    "            OEff = {\"Rolling4OEff\":teamRollingOEff}\n",
    "            OEff4df = pd.DataFrame.from_dict(OEff)\n",
    "            OEff4DB = pd.concat([OEff4DB, OEff4df])\n",
    "\n",
    "        DEff4DB = pd.DataFrame()\n",
    "        rollingDEff = []\n",
    "        for team in db['Team'].unique():\n",
    "            teamRollingDEff = db[db['Team'] == team]['DEff'].rolling(4).mean()\n",
    "            rollingDEff.append(teamRollingDEff)\n",
    "            DEff = {\"Rolling4DEff\":teamRollingDEff}\n",
    "            DEff4df = pd.DataFrame.from_dict(DEff)\n",
    "            DEff4DB = pd.concat([DEff4DB, DEff4df])\n",
    "\n",
    "        db = pd.concat([db, TSP4DB, TOV4DB, ORB4DB, FTR4DB, Poss4DB, OEff4DB, DEff4DB], axis =1)\n",
    "\n",
    "        return db\n",
    "\n",
    "    db['Opp PTS'] = np.zeros(len(db))\n",
    "    db['Opp TRB'] = np.zeros(len(db))\n",
    "    db['Opp ORB'] = np.zeros(len(db))\n",
    "\n",
    "    for i, opp in enumerate(db['Opp']):\n",
    "        db['Opp PTS'][i] = db[(db['Team'] == opp) & (db['Date'] == db['Date'][i])]['PTS']\n",
    "        db['Opp TRB'][i] = db[(db['Team'] == opp) & (db['Date'] == db['Date'][i])]['TRB']\n",
    "        db['Opp ORB'][i] = db[(db['Team'] == opp) & (db['Date'] == db['Date'][i])]['ORB']        \n",
    "\n",
    "    db['TS%'] = np.zeros(len(db))\n",
    "    db['TOV%'] = np.zeros(len(db))\n",
    "    db['ORB%'] = np.zeros(len(db))\n",
    "    db['FTR'] = np.zeros(len(db))\n",
    "    db['Poss'] = np.zeros(len(db))\n",
    "    db['OEff'] = np.zeros(len(db))\n",
    "    db['DEff'] = np.zeros(len(db))\n",
    "\n",
    "    for i in range(len(db)):\n",
    "        db['TS%'][i] = db['PTS'][i] / (db['FGA'][i] + .44*db['FTA'][i]) * 0.5\n",
    "        db['TOV%'][i] = db['TOV'][i] / (db['FGA'][i] + .44*db['FTA'][i] + db['TOV'][i])\n",
    "        db['ORB%'][i] = db['ORB'][i] / (db['ORB'][i] + (db['Opp TRB'][i] - db['Opp ORB'][i]))\n",
    "        db['FTR'][i] = db['FT'][i] / db['FGA'][i]\n",
    "        db['Poss'][i] = 0.96 * db['FGA'][i] + db['TOV'][i] + 0.44*db['FTA'][i] - db['ORB'][i]\n",
    "        db['OEff'][i] = 100* db['PTS'][i]/db['Poss'][i]\n",
    "        # db['DEff'][i] = opponenets OEff; use indexing after this step\n",
    "\n",
    "    db['Opp TS%'] = np.zeros(len(db))\n",
    "    db['Opp TOV%'] = np.zeros(len(db))\n",
    "    db['Opp ORB%'] = np.zeros(len(db))\n",
    "    db['Opp FTR'] = np.zeros(len(db))\n",
    "    db['Opp Poss'] = np.zeros(len(db))\n",
    "    db['Opp OEff'] = np.zeros(len(db))\n",
    "    db['Opp DEff'] = np.zeros(len(db))\n",
    "\n",
    "    for i, opp in enumerate(db['Opp']):\n",
    "        db['DEff'][i] = db[(db['Team'] == opp) & (db['Date'] == db['Date'][i])]['OEff']\n",
    "        db['Opp TS%'][i] = db[(db['Team'] == opp) & (db['Date'] == db['Date'][i])]['TS%']\n",
    "        db['Opp TOV%'][i] = db[(db['Team'] == opp) & (db['Date'] == db['Date'][i])]['TOV%']\n",
    "        db['Opp ORB%'][i] = db[(db['Team'] == opp) & (db['Date'] == db['Date'][i])]['ORB%']\n",
    "        db['Opp FTR'][i] = db[(db['Team'] == opp) & (db['Date'] == db['Date'][i])]['FTR']\n",
    "        db['Opp Poss'][i] = db[(db['Team'] == opp) & (db['Date'] == db['Date'][i])]['Poss']\n",
    "        db['Opp OEff'][i] = db[(db['Team'] == opp) & (db['Date'] == db['Date'][i])]['OEff']\n",
    "\n",
    "    for i, opp in enumerate(db['Opp']):\n",
    "        db['Opp DEff'][i] = db[(db['Team'] == opp) & (db['Date'] == db['Date'][i])]['DEff']\n",
    "\n",
    "    db = rolling_avgs(db)\n",
    "    \n",
    "    db['Opp R4TSP'] = np.zeros(len(db['Team']))\n",
    "    db['Opp R4TOV'] = np.zeros(len(db['Team']))\n",
    "    db['Opp R4ORB'] = np.zeros(len(db['Team']))\n",
    "    db['Opp R4FTR'] = np.zeros(len(db['Team']))\n",
    "    db['Opp R4Poss'] = np.zeros(len(db['Team']))\n",
    "    db['Opp R4OEff'] = np.zeros(len(db['Team']))\n",
    "    db['Opp R4DEff'] = np.zeros(len(db['Team']))\n",
    "\n",
    "    for i, opp in enumerate(db['Opp']):\n",
    "        db['Opp R4TSP'][i] = db[(db['Team'] == opp) & (db['Date'] == db['Date'][i])]['Rolling4TSP']\n",
    "        db['Opp R4TOV'][i] = db[(db['Team'] == opp) & (db['Date'] == db['Date'][i])]['Rolling4TOV']\n",
    "        db['Opp R4ORB'][i] = db[(db['Team'] == opp) & (db['Date'] == db['Date'][i])]['Rolling4ORB']\n",
    "        db['Opp R4FTR'][i] = db[(db['Team'] == opp) & (db['Date'] == db['Date'][i])]['Rolling4FTR']\n",
    "        db['Opp R4Poss'][i] = db[(db['Team'] == opp) & (db['Date'] == db['Date'][i])]['Rolling4Poss']\n",
    "        db['Opp R4OEff'][i] = db[(db['Team'] == opp) & (db['Date'] == db['Date'][i])]['Rolling4OEff']\n",
    "        db['Opp R4DEff'][i] = db[(db['Team'] == opp) & (db['Date'] == db['Date'][i])]['Rolling4DEff']\n",
    "    \n",
    "    \n",
    "    return db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def today_games(date):\n",
    "    \n",
    "    # Date format YYYMMDD\n",
    "    \n",
    "    bet_abbrevs = {\n",
    "        'Atlanta Dream': 'ATL',\n",
    "        'Washington Mystics': 'WAS',\n",
    "        'Connecticut Sun': 'CON',\n",
    "        'Chicago Sky': 'CHI',\n",
    "        'New York Liberty': 'NYL',\n",
    "        'Indiana Fever': 'IND',\n",
    "        'Seattle Storm': 'SEA',\n",
    "        'Phoenix Mercury': 'PHO',\n",
    "        'L.A. Sparks':'LAS',\n",
    "        'Minnesota Lynx': 'MIN',\n",
    "        'Dallas Wings': 'DAL',\n",
    "        'Las Vegas Aces': 'LVA'\n",
    "    }\n",
    "\n",
    "    moneydb = pd.DataFrame()\n",
    "    \n",
    "    print(\"Date: \", date)\n",
    "    url = f'https://www.sportsbookreview.com/betting-odds/wnba-basketball/money-line/?date={date}'\n",
    "    res = requests.get(url, 'html.parser')\n",
    "    res.raise_for_status()\n",
    "    soup = bs4.BeautifulSoup(res.text, 'lxml')\n",
    "    linesoup = soup.find('div', {'id':'bettingOddsGridContainer'})\n",
    "    test_teams = linesoup.find_all('span', {'class':'_3O1Gx'})\n",
    "    teams = [bet_abbrevs[team.get_text()] for team in test_teams]\n",
    "    test_lines = linesoup.find_all('span', {'class':'opener'})\n",
    "    lines = [line.get_text() for line in test_lines if line.get_text().startswith('-') and len(line.get_text()) > 1 or line.get_text().startswith('+') and len(line.get_text()) > 1]\n",
    "    #print(\"teams:\",len(teams),\"lines\",len(lines))\n",
    "\n",
    "    while len(teams) != len(lines):\n",
    "        lines.append(np.nan)\n",
    "        \n",
    "    moneylines = {'Team':teams, 'ML Odds': lines, 'Date':[date]*len(teams)}\n",
    "\n",
    "    MLdb = pd.DataFrame.from_dict(moneylines)\n",
    "    moneydb = pd.concat([moneydb, MLdb])\n",
    "    \n",
    "    if len(moneydb) == 0:\n",
    "        print (\"No games today\")\n",
    "    else:\n",
    "        return moneydb.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_games(db, games):\n",
    "    db14 = pd.read_csv('WNBA14.csv')\n",
    "    db15 = pd.read_csv('WNBA15.csv')\n",
    "    db16 = pd.read_csv('WNBA16.csv')\n",
    "    db17 = pd.read_csv('WNBA17.csv')\n",
    "    db18 = pd.read_csv('WNBA18.csv')\n",
    "    \n",
    "    predict_db = pd.concat([db14, db15, db16, db17, db18]).reset_index(drop = True)\n",
    "\n",
    "    Team = []\n",
    "    Opp = []\n",
    "    Location = []\n",
    "    Rolling4TSP = []\n",
    "    Rolling4TOV = []\n",
    "    Rolling4ORB = []\n",
    "    Rolling4FTR = []\n",
    "    Rolling4Poss = []\n",
    "    OppR4Poss = []\n",
    "    OppR4TSP = []\n",
    "    OppR4TOV = []\n",
    "    OppR4ORB = []\n",
    "    OppR4FTR = []\n",
    "    Rolling4DEff = []\n",
    "    OppR4DEff = []\n",
    "    Rolling4OEff = []\n",
    "    OppR4OEff = []\n",
    "    \n",
    "    for i, team in enumerate(games['Team']):\n",
    "        if i%2 == 0:\n",
    "            Location.append(0)\n",
    "            Opp.append(games['Team'][i+1])\n",
    "        else:\n",
    "            Location.append(1)\n",
    "            Opp.append(games['Team'][i-1])\n",
    "        \n",
    "        Team.append(team)\n",
    "        Rolling4TSP.append(db[db['Team'] == team]['Rolling4TSP'].iloc[-1])\n",
    "        Rolling4TOV.append(db[db['Team'] == team]['Rolling4TOV'].iloc[-1])\n",
    "        Rolling4ORB.append(db[db['Team'] == team]['Rolling4ORB'].iloc[-1])\n",
    "        Rolling4FTR.append(db[db['Team'] == team]['Rolling4FTR'].iloc[-1])\n",
    "        Rolling4Poss.append(db[db['Team'] == team]['Rolling4Poss'].iloc[-1])\n",
    "        Rolling4DEff.append(db[db['Team'] == team]['Rolling4DEff'].iloc[-1])\n",
    "        Rolling4OEff.append(db[db['Team'] == team]['Rolling4OEff'].iloc[-1])\n",
    "    \n",
    "    data = {\"Team\": Team, 'Opponent': Opp, \"Location\":Location, 'Rolling4TSP': Rolling4TSP, 'Rolling4TOV':Rolling4TOV, \n",
    "            'Rolling4ORB':Rolling4ORB, \"Rolling4FTR\":Rolling4FTR, 'Rolling4Poss':Rolling4Poss, \n",
    "            'Rolling4DEff':Rolling4DEff, 'Rolling4OEff':Rolling4OEff}\n",
    "        \n",
    "    data = pd.DataFrame(data)\n",
    "    \n",
    "    data['Opp R4Poss'] = np.zeros(len(data))\n",
    "    data['Opp R4TSP'] = np.zeros(len(data))\n",
    "    data['Opp R4TOV'] = np.zeros(len(data))\n",
    "    data['Opp R4ORB'] = np.zeros(len(data))\n",
    "    data['Opp R4FTR'] = np.zeros(len(data))\n",
    "    data['Opp R4DEff'] = np.zeros(len(data))\n",
    "    data['Opp R4OEff'] = np.zeros(len(data))\n",
    "    \n",
    "    for i, team in enumerate(data['Opponent']):\n",
    "        data['Opp R4Poss'][i] = db[db['Team'] == team]['Rolling4Poss'].iloc[-1]\n",
    "        data['Opp R4TSP'][i] = db[db['Team'] == team]['Rolling4TSP'].iloc[-1]\n",
    "        data['Opp R4TOV'][i] = db[db['Team'] == team]['Rolling4TOV'].iloc[-1]\n",
    "        data['Opp R4ORB'][i] = db[db['Team'] == team]['Rolling4ORB'].iloc[-1]\n",
    "        data['Opp R4FTR'][i] = db[db['Team'] == team]['Rolling4FTR'].iloc[-1]\n",
    "        data['Opp R4DEff'][i] = db[db['Team'] == team]['Rolling4DEff'].iloc[-1]\n",
    "        data['Opp R4OEff'][i] = db[db['Team'] == team]['Rolling4DEff'].iloc[-1]\n",
    "    \n",
    "    featureCols = ['Location','Rolling4TSP','Rolling4TOV','Rolling4ORB',\n",
    "                   'Rolling4FTR','Rolling4Poss','Opp R4Poss','Opp R4TSP',\n",
    "                   'Opp R4TOV','Opp R4ORB','Opp R4FTR', 'Rolling4DEff', \n",
    "                   'Opp R4DEff', 'Rolling4OEff','Opp R4OEff']\n",
    "    target = ['Result']\n",
    "\n",
    "    cols =  ['Result', 'Location','Rolling4TSP','Rolling4TOV','Rolling4ORB','Rolling4FTR','Rolling4Poss','Opp R4Poss','Opp R4TSP','Opp R4TOV','Opp R4ORB','Opp R4FTR', 'Rolling4DEff', 'Opp R4DEff', 'Rolling4OEff','Opp R4OEff']\n",
    "    predict_db = predict_db[cols].dropna()\n",
    "    \n",
    "    X = predict_db[featureCols]\n",
    "    y = np.array(predict_db[target]).flatten()\n",
    "\n",
    "    preds_avg = []\n",
    "\n",
    "    for i in range(50):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "        ada = AdaBoostClassifier(n_estimators=100, learning_rate=0.1).fit(x_train, y_train)\n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "        gbc = GradientBoostingClassifier(n_estimators=500, learning_rate=0.1, max_depth=1).fit(x_train, y_train)\n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "        eclf1 = VotingClassifier(estimators=[('ada', ada), ('gbc', gbc)], voting='soft')\n",
    "        eclf1 = eclf1.fit(x_train, y_train)\n",
    "\n",
    "        pred = eclf1.predict(data[featureCols].dropna())\n",
    "\n",
    "        preds_avg.append(pred)\n",
    "        \n",
    "    preds = [sum(i) for i in zip(*preds_avg)]\n",
    "    preds = pd.DataFrame({\"Prediction\": preds})\n",
    "    return print(pd.concat([data.dropna().reset_index(drop = True), preds], axis = 1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_script():\n",
    "    print('Gathering stats...')\n",
    "    db = wnba_update(2019)\n",
    "    print(\"Formatting...\")\n",
    "    db = db_format(db)\n",
    "    print(\"Fetching today's games...\")\n",
    "    games = today_games(20190620)\n",
    "    print(\"Predicting...\")\n",
    "    predict_games(db, games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering stats...\n",
      "ATL\n",
      "WAS\n",
      "CON\n",
      "CHI\n",
      "NYL\n",
      "IND\n",
      "SEA\n",
      "PHO\n",
      "LAS\n",
      "MIN\n",
      "DAL\n",
      "LVA\n",
      "Formatting...\n",
      "Fetching today's games...\n",
      "Date:  20190620\n",
      "Predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ahelgeso/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Team Opponent  Location  Rolling4TSP  Rolling4TOV  Rolling4ORB  Rolling4FTR  \\\n",
      "0  PHO      DAL         0     0.489128     0.139037     0.246013     0.197361   \n",
      "1  DAL      PHO         1     0.455550     0.145701     0.329953     0.162595   \n",
      "2  WAS      LVA         0     0.525122     0.135346     0.215621     0.196264   \n",
      "3  LVA      WAS         1     0.554881     0.176693     0.283662     0.300536   \n",
      "\n",
      "   Rolling4Poss  Rolling4DEff  Rolling4OEff  Opp R4Poss  Opp R4TSP  Opp R4TOV  \\\n",
      "0         74.48    104.194263     97.876954       71.69   0.455550   0.145701   \n",
      "1         71.69    103.310761     93.753780       74.48   0.489128   0.139037   \n",
      "2         76.11     89.093633    102.798261       83.53   0.554881   0.176693   \n",
      "3         83.53     89.466599    104.624213       76.11   0.525122   0.135346   \n",
      "\n",
      "   Opp R4ORB  Opp R4FTR  Opp R4DEff  Opp R4OEff  Prediction  \n",
      "0   0.329953   0.162595  103.310761  103.310761           0  \n",
      "1   0.246013   0.197361  104.194263  104.194263          30  \n",
      "2   0.283662   0.300536   89.466599   89.466599          46  \n",
      "3   0.215621   0.196264   89.093633   89.093633          50  \n"
     ]
    }
   ],
   "source": [
    "run_script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
