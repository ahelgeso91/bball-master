{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import requests, bs4\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db19 = pd.read_csv('2019stats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check results using 2016-2018 data on 2019 games "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pd.read_csv('2017_2018stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature3Cols = ['Location','Rolling3EFG','Rolling3TOV','Rolling3ORB','Rolling3FTR','Rolling3Pace','Opp R3Pace','Opp R3EFG','Opp R3TOV','Opp R3ORB','Opp R3FTR', 'Rolling3DEff', 'Opp R3 Deff', 'Rolling3OEff','Opp R3 Oeff']\n",
    "feature9Cols = ['Location','Rolling9EFG','Rolling9TOV','Rolling9ORB','Rolling9FTR','Rolling9Pace','Opp R9Pace','Opp R9EFG','Opp R9TOV','Opp R9ORB','Opp R9FTR', 'Rolling9DEff', 'Opp R9 Deff', 'Rolling3OEff','Opp R3 Oeff']\n",
    "\n",
    "target = ['Result']\n",
    "X3 = db.dropna()[feature3Cols]\n",
    "X9 = db.dropna()[feature9Cols]\n",
    "y = np.array(db.dropna()[target]).flatten()\n",
    "svc=SVC(probability=True)\n",
    "\n",
    "x9_train, x9_test, y9_train, y9_test = train_test_split(X9, y, test_size=0.3, random_state=1)\n",
    "x3_train, x3_test, y3_train, y3_test = train_test_split(X3, y, test_size=0.3, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All picks (R9): 0.6293759512937596\n",
      "All picks (R9) matrix:\n",
      " [[442 208]\n",
      " [279 385]]\n",
      " \n",
      "0.6299096385542168\n",
      "All picks (R3): 0.5905631659056316\n",
      "All picks (R3) matrix:\n",
      " [[430 220]\n",
      " [318 346]]\n",
      "0.5913113994439296\n",
      " \n"
     ]
    }
   ],
   "source": [
    "bag9 = BaggingClassifier( n_estimators=20, random_state=1).fit(x9_train, y9_train)\n",
    "pred = bag9.predict(x9_test)\n",
    "print('All picks (R9):',bag9.score(x9_test, y9_test))\n",
    "print('All picks (R9) matrix:\\n',confusion_matrix(y9_test, pred))\n",
    "print(' ')\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y9_test, pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(roc_auc)\n",
    "\n",
    "bag3 = BaggingClassifier(n_estimators=20, random_state=1).fit(x3_train, y3_train)\n",
    "pred = bag3.predict(x3_test)\n",
    "print('All picks (R3):',bag3.score(x3_test, y3_test))\n",
    "print('All picks (R3) matrix:\\n',confusion_matrix(y3_test, pred))\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y3_test, pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(roc_auc)\n",
    "print(' ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2019 test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs2019 = db19[(db19['Line'] > 0)].dropna().reset_index()\n",
    "Ydogs2019 = db19[(db19['Line'] > 0)].dropna()['Result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dog data[rolling 9 averages]: \n",
      "\n",
      "Using 9 game standard predictor: \n",
      "Dog picks: 0.6402609506057781\n",
      "Dog picks matrix:\n",
      " [[568 148]\n",
      " [238 119]]\n",
      "\n",
      "Using 3 game standard predictor: \n",
      "Dog picks: 0.6169617893755824\n",
      "Dog picks matrix:\n",
      " [[508 208]\n",
      " [203 154]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Using dog data[rolling 9 averages]: \\n\")\n",
    "\n",
    "print(\"Using 9 game standard predictor: \")\n",
    "pred1 = bag9.predict(dogs2019[feature9Cols])\n",
    "print('Dog picks:',bag9.score(dogs2019[feature9Cols], Ydogs2019))\n",
    "print('Dog picks matrix:\\n',confusion_matrix(Ydogs2019, pred1))\n",
    "print('')\n",
    "\n",
    "print(\"Using 3 game standard predictor: \")\n",
    "pred2 = bag3.predict(dogs2019[feature9Cols])\n",
    "print('Dog picks:',bag3.score(dogs2019[feature9Cols], Ydogs2019))\n",
    "print('Dog picks matrix:\\n',confusion_matrix(Ydogs2019, pred2))\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odds = []\n",
    "for i, n in enumerate(pred1):\n",
    "    if n == 1:\n",
    "        odds.append(dogs2019['Odds'][i])\n",
    "import statistics\n",
    "statistics.mean(odds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing great"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using rolling 3 averages: \n",
      "\n",
      "Using 9 game standard predictor: \n",
      "Dog picks: 0.5945945945945946\n",
      "Dog picks matrix:\n",
      " [[495 221]\n",
      " [214 143]]\n",
      "\n",
      "Using 3 game standard predictor: \n",
      "Dog picks: 0.6132339235787512\n",
      "Dog picks matrix:\n",
      " [[502 214]\n",
      " [201 156]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Using rolling 3 averages: \\n\")\n",
    "\n",
    "print(\"Using 9 game standard predictor: \")\n",
    "pred1 = bag9.predict(dogs2019[feature3Cols])\n",
    "print('Dog picks:',bag9.score(dogs2019[feature3Cols], Ydogs2019))\n",
    "print('Dog picks matrix:\\n',confusion_matrix(Ydogs2019, pred1))\n",
    "print('')\n",
    "\n",
    "print(\"Using 3 game standard predictor: \")\n",
    "pred2 = bag3.predict(dogs2019[feature3Cols])\n",
    "print('Dog picks:',bag3.score(dogs2019[feature3Cols], Ydogs2019))\n",
    "print('Dog picks matrix:\\n',confusion_matrix(Ydogs2019, pred2))\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217\n",
      "175.0\n",
      "204\n",
      "165.0\n"
     ]
    }
   ],
   "source": [
    "odds = []\n",
    "for i, n in enumerate(pred1):\n",
    "    if n == 1:\n",
    "        odds.append(dogs2019['Odds'][i])\n",
    "        \n",
    "print(statistics.mean(odds))\n",
    "print(statistics.median(odds))\n",
    "\n",
    "odds = []\n",
    "for i, n in enumerate(pred2):\n",
    "    if n == 1:\n",
    "        odds.append(dogs2019['Odds'][i])\n",
    "        \n",
    "print(statistics.mean(odds))\n",
    "print(statistics.median(odds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nothing great"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now what I wanna do is build a model off 2018 data while continuously rolling in 2019 data as if the season was ongoing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pd.read_csv('2018stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature3Cols = ['Location','Rolling3EFG','Rolling3TOV','Rolling3ORB','Rolling3FTR','Rolling3Pace','Opp R3Pace','Opp R3EFG','Opp R3TOV','Opp R3ORB','Opp R3FTR']\n",
    "#feature9Cols = ['Location','Rolling9EFG','Rolling9TOV','Rolling9ORB','Rolling9FTR','Rolling9Pace','Opp R9Pace','Opp R9EFG','Opp R9TOV','Opp R9ORB','Opp R9FTR']\n",
    "\n",
    "#target = ['Result']\n",
    "X3 = db.dropna()[feature3Cols]\n",
    "X9 = db.dropna()[feature9Cols]\n",
    "y = np.array(db.dropna()[target]).flatten()\n",
    "\n",
    "x9_train, x9_test, y9_train, y9_test = train_test_split(X9, y, test_size=0.3, random_state=8)\n",
    "x3_train, x3_test, y3_train, y3_test = train_test_split(X3, y, test_size=0.3, random_state=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All picks (R9): 0.6293759512937596\n",
      "All picks (R9) matrix:\n",
      " [[442 208]\n",
      " [279 385]]\n",
      " \n",
      "0.6299096385542168\n",
      "All picks (R3): 0.5905631659056316\n",
      "All picks (R3) matrix:\n",
      " [[430 220]\n",
      " [318 346]]\n",
      "0.5913113994439296\n",
      " \n"
     ]
    }
   ],
   "source": [
    "bag9 = BaggingClassifier(n_estimators=20, random_state=1).fit(x9_train, y9_train)\n",
    "pred = bag9.predict(x9_test)\n",
    "print('All picks (R9):',bag9.score(x9_test, y9_test))\n",
    "print('All picks (R9) matrix:\\n',confusion_matrix(y9_test, pred))\n",
    "print(' ')\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y9_test, pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(roc_auc)\n",
    "\n",
    "bag3 = BaggingClassifier(n_estimators=20, random_state=1).fit(x3_train, y3_train)\n",
    "pred = bag3.predict(x3_test)\n",
    "print('All picks (R3):',bag3.score(x3_test, y3_test))\n",
    "print('All picks (R3) matrix:\\n',confusion_matrix(y3_test, pred))\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y3_test, pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(roc_auc)\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs2019 = db19[db19['Line'] > 0].dropna().reset_index()\n",
    "Ydogs2019 = db19[db19['Line'] > 0].dropna()['Result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dog data[rolling 9 averages]: \n",
      "\n",
      "Using 9 game standard predictor: \n",
      "Dog picks: 0.6402609506057781\n",
      "Dog picks matrix:\n",
      " [[568 148]\n",
      " [238 119]]\n",
      "\n",
      "Using 3 game standard predictor: \n",
      "Dog picks: 0.6169617893755824\n",
      "Dog picks matrix:\n",
      " [[508 208]\n",
      " [203 154]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Using dog data[rolling 9 averages]: \\n\")\n",
    "\n",
    "print(\"Using 9 game standard predictor: \")\n",
    "pred1 = bag9.predict(dogs2019[feature9Cols])\n",
    "print('Dog picks:',bag9.score(dogs2019[feature9Cols], Ydogs2019))\n",
    "print('Dog picks matrix:\\n',confusion_matrix(Ydogs2019, pred1))\n",
    "print('')\n",
    "\n",
    "print(\"Using 3 game standard predictor: \")\n",
    "pred2 = bag3.predict(dogs2019[feature9Cols])\n",
    "print('Dog picks:',bag3.score(dogs2019[feature9Cols], Ydogs2019))\n",
    "print('Dog picks matrix:\\n',confusion_matrix(Ydogs2019, pred2))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First model is the best one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average odds 1: 166\n",
      "Median odds 1: 155\n",
      "Average odds 2: 211\n",
      "Median odds 2: 160.0\n"
     ]
    }
   ],
   "source": [
    "odds = []\n",
    "for i, n in enumerate(pred1):\n",
    "    if n == 1:\n",
    "        odds.append(dogs2019['Odds'][i])\n",
    "        \n",
    "print(\"Average odds 1:\", statistics.mean(odds))\n",
    "print(\"Median odds 1:\", statistics.median(odds))\n",
    "\n",
    "odds = []\n",
    "for i, n in enumerate(pred2):\n",
    "    if n == 1:\n",
    "        odds.append(dogs2019['Odds'][i])\n",
    "        \n",
    "print(\"Average odds 2:\", statistics.mean(odds))\n",
    "print(\"Median odds 2:\", statistics.median(odds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using rolling 3 averages: \n",
      "\n",
      "Using 9 game standard predictor: \n",
      "Dog picks: 0.5945945945945946\n",
      "Dog picks matrix:\n",
      " [[495 221]\n",
      " [214 143]]\n",
      "\n",
      "Using 3 game standard predictor: \n",
      "Dog picks: 0.6132339235787512\n",
      "Dog picks matrix:\n",
      " [[502 214]\n",
      " [201 156]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Using rolling 3 averages: \\n\")\n",
    "\n",
    "print(\"Using 9 game standard predictor: \")\n",
    "pred1 = bag9.predict(dogs2019[feature3Cols])\n",
    "print('Dog picks:',bag9.score(dogs2019[feature3Cols], Ydogs2019))\n",
    "print('Dog picks matrix:\\n',confusion_matrix(Ydogs2019, pred1))\n",
    "print('')\n",
    "\n",
    "print(\"Using 3 game standard predictor: \")\n",
    "pred2 = bag3.predict(dogs2019[feature3Cols])\n",
    "print('Dog picks:',bag3.score(dogs2019[feature3Cols], Ydogs2019))\n",
    "print('Dog picks matrix:\\n',confusion_matrix(Ydogs2019, pred2))\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average odds 1: 217\n",
      "Median odds 1: 175.0\n",
      "Average odds 2: 204\n",
      "Median odds 2: 165.0\n"
     ]
    }
   ],
   "source": [
    "odds = []\n",
    "for i, n in enumerate(pred1):\n",
    "    if n == 1:\n",
    "        odds.append(dogs2019['Odds'][i])\n",
    "        \n",
    "print(\"Average odds 1:\", statistics.mean(odds))\n",
    "print(\"Median odds 1:\", statistics.median(odds))\n",
    "\n",
    "odds = []\n",
    "for i, n in enumerate(pred2):\n",
    "    if n == 1:\n",
    "        odds.append(dogs2019['Odds'][i])\n",
    "        \n",
    "print(\"Average odds 2:\", statistics.mean(odds))\n",
    "print(\"Median odds 2:\", statistics.median(odds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing great"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "db19 = pd.read_csv('2019stats.csv')\n",
    "db = pd.read_csv('2018stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#db19.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis = 1, inplace = True)\n",
    "db19['Date'] = db19['Date'].apply(str)\n",
    "db19['Date'] = pd.to_datetime(db19.Date, format = \"%Y%m%d\")\n",
    "db19 = db19.sort_values(by = ['Date']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "db['Date'] = db['Date'].apply(str)\n",
    "db['Date'] = pd.to_datetime(db.Date, format= \"%Y%m%d\")\n",
    "db = db.sort_values(by = ['Date']).reset_index(drop = True)\n",
    "test = pd.concat([db, db19[:int(len(db19)/2)]], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave in first half of prev season or cut it out?\n",
    "\n",
    "test = test.drop(test.index[:int(len(db19)/2)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = test.reset_index(drop = True) ### for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = db.drop(['Implied Prob','Implied Proba','Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is a realistic expectation of what a running database may look like. I added half the season's worth of 2019 onto the 2018 db, and dropped the first half of 2018. The model now looks at the second half of 2018 and the first half of 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature3Cols = ['Location','Rolling3EFG','Rolling3TOV','Rolling3ORB','Rolling3FTR','Rolling3Pace','Opp R3Pace','Opp R3EFG','Opp R3TOV','Opp R3ORB','Opp R3FTR']\n",
    "#feature9Cols = ['Location','Rolling9EFG','Rolling9TOV','Rolling9ORB','Rolling9FTR','Rolling9Pace','Opp R9Pace','Opp R9EFG','Opp R9TOV','Opp R9ORB','Opp R9FTR']\n",
    "\n",
    "target = ['Result']\n",
    "X3 = db.dropna()[feature3Cols]\n",
    "X9 = db.dropna()[feature9Cols]\n",
    "y = np.array(db.dropna()[target]).flatten()\n",
    "\n",
    "\n",
    "x9_train, x9_test, y9_train, y9_test = train_test_split(X9, y, test_size=0.3, random_state=3)\n",
    "x3_train, x3_test, y3_train, y3_test = train_test_split(X3, y, test_size=0.3, random_state=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All picks (R9): 0.636986301369863\n",
      "All picks (R9) matrix:\n",
      " [[441 209]\n",
      " [268 396]]\n",
      "0.6374235403151065\n",
      " \n",
      "All picks (R3): 0.6111111111111112\n",
      "All picks (R3) matrix:\n",
      " [[424 226]\n",
      " [285 379]]\n",
      "0.6115454124189064\n",
      " \n"
     ]
    }
   ],
   "source": [
    "bag9 = BaggingClassifier(n_estimators=20, random_state=3).fit(x9_train, y9_train)\n",
    "pred = bag9.predict(x9_test)\n",
    "print('All picks (R9):',bag9.score(x9_test, y9_test))\n",
    "print('All picks (R9) matrix:\\n',confusion_matrix(y9_test, pred))\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y9_test, pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(roc_auc)\n",
    "print(' ')\n",
    "\n",
    "bag3 = BaggingClassifier(n_estimators=20, random_state=3).fit(x3_train, y3_train)\n",
    "pred = bag3.predict(x3_test)\n",
    "print('All picks (R3):',bag3.score(x3_test, y3_test))\n",
    "print('All picks (R3) matrix:\\n',confusion_matrix(y3_test, pred))\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y3_test, pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(roc_auc)\n",
    "print(' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ahelgeso/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/ahelgeso/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "dogs2019 = db19[int(len(db19)/2):][db19['Line'] > 0].dropna().reset_index()\n",
    "Ydogs2019 = db19[int(len(db19)/2):][db19['Line'] > 0].dropna()['Result']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is now predicting all underdog games for last half of season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dog data[rolling 9 averages]: \n",
      "\n",
      "Using 9 game standard predictor: \n",
      "Dog picks: 0.6495867768595042\n",
      "Dog picks matrix:\n",
      " [[332  80]\n",
      " [132  61]]\n",
      "\n",
      "Using 3 game standard predictor: \n",
      "Dog picks: 0.6297520661157024\n",
      "Dog picks matrix:\n",
      " [[307 105]\n",
      " [119  74]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Using dog data[rolling 9 averages]: \\n\")\n",
    "\n",
    "print(\"Using 9 game standard predictor: \")\n",
    "pred1 = bag9.predict(dogs2019[feature9Cols])\n",
    "print('Dog picks:',bag9.score(dogs2019[feature9Cols], Ydogs2019))\n",
    "print('Dog picks matrix:\\n',confusion_matrix(Ydogs2019, pred1))\n",
    "print('')\n",
    "\n",
    "print(\"Using 3 game standard predictor: \")\n",
    "pred2 = bag3.predict(dogs2019[feature9Cols])\n",
    "print('Dog picks:',bag3.score(dogs2019[feature9Cols], Ydogs2019))\n",
    "print('Dog picks matrix:\\n',confusion_matrix(Ydogs2019, pred2))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average odds: 153\n",
      "Median odds: 155\n",
      "Average odds: 187\n",
      "Median odds: 165\n"
     ]
    }
   ],
   "source": [
    "odds = []\n",
    "for i, n in enumerate(pred1):\n",
    "    if n == 1:\n",
    "        odds.append(dogs2019['Odds'][i])\n",
    "\n",
    "print(\"Average odds:\", statistics.mean(odds))\n",
    "print(\"Median odds:\", statistics.median(odds))\n",
    "\n",
    "odds = []\n",
    "for i, n in enumerate(pred2):\n",
    "    if n == 1:\n",
    "        odds.append(dogs2019['Odds'][i])\n",
    "\n",
    "print(\"Average odds:\", statistics.mean(odds))\n",
    "print(\"Median odds:\", statistics.median(odds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using rolling 3 averages: \n",
      "\n",
      "Using 9 game standard predictor: \n",
      "Dog picks: 0.6297520661157024\n",
      "Dog picks matrix:\n",
      " [[306 106]\n",
      " [118  75]]\n",
      "\n",
      "Using 3 game standard predictor: \n",
      "Dog picks: 0.6396694214876033\n",
      "Dog picks matrix:\n",
      " [[306 106]\n",
      " [112  81]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Using rolling 3 averages: \\n\")\n",
    "\n",
    "print(\"Using 9 game standard predictor: \")\n",
    "pred1 = bag9.predict(dogs2019[feature3Cols])\n",
    "print('Dog picks:',bag9.score(dogs2019[feature3Cols], Ydogs2019))\n",
    "print('Dog picks matrix:\\n',confusion_matrix(Ydogs2019, pred1))\n",
    "print('')\n",
    "\n",
    "print(\"Using 3 game standard predictor: \")\n",
    "pred2 = bag3.predict(dogs2019[feature3Cols])\n",
    "print('Dog picks:',bag3.score(dogs2019[feature3Cols], Ydogs2019))\n",
    "print('Dog picks matrix:\\n',confusion_matrix(Ydogs2019, pred2))\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average odds: 202\n",
      "Median odds: 175\n",
      "Average odds: 216\n",
      "Median odds: 170\n"
     ]
    }
   ],
   "source": [
    "odds = []\n",
    "for i, n in enumerate(pred1):\n",
    "    if n == 1:\n",
    "        odds.append(dogs2019['Odds'][i])\n",
    "\n",
    "print(\"Average odds:\", statistics.mean(odds))\n",
    "print(\"Median odds:\", statistics.median(odds))\n",
    "\n",
    "odds = []\n",
    "for i, n in enumerate(pred2):\n",
    "    if n == 1:\n",
    "        odds.append(dogs2019['Odds'][i])\n",
    "\n",
    "print(\"Average odds:\", statistics.mean(odds))\n",
    "print(\"Median odds:\", statistics.median(odds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model drops 2018 data when adding first half of 2019.\n",
    "\n",
    "The 3-game predictor goes 74-105 using 9-game average data, with average odds of 187.\n",
    "\n",
    "The 3-game predictor goes 81-106 using 3-game average data, with average odds of 216."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_filename = \"GBC9model.pkl\"  \n",
    "with open(pkl_filename, 'wb') as file:  \n",
    "    pickle.dump(clfgtb9, file)\n",
    "    \n",
    "pkl_filename = \"GBC3model.pkl\"  \n",
    "with open(pkl_filename, 'wb') as file:  \n",
    "    pickle.dump(clfgtb3, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ahelgeso/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 0.20.3 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/ahelgeso/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator GradientBoostingClassifier from version 0.20.3 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "model3 = pickle.load(open('GBC3Model.pkl', 'rb'))\n",
    "model9 = pickle.load(open('GBC9Model.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dog data[rolling 9 averages]: \n",
      "\n",
      "Using 9 game standard predictor: \n",
      "Dog picks: 0.6264462809917355\n",
      "Dog picks matrix:\n",
      " [[309 103]\n",
      " [123  70]]\n",
      "\n",
      "Using 3 game standard predictor: \n",
      "Dog picks: 0.6264462809917355\n",
      "Dog picks matrix:\n",
      " [[316  96]\n",
      " [130  63]]\n",
      "\n",
      "Average odds: 191.9364161849711\n",
      "Median odds: 165.0\n",
      "Average odds: 192.0251572327044\n",
      "Median odds: 160.0\n",
      "\n",
      "Using rolling 3 averages: \n",
      "\n",
      "Using 9 game standard predictor: \n",
      "Dog picks: 0.6082644628099173\n",
      "Dog picks matrix:\n",
      " [[281 131]\n",
      " [106  87]]\n",
      "\n",
      "Using 3 game standard predictor: \n",
      "Dog picks: 0.6099173553719008\n",
      "Dog picks matrix:\n",
      " [[288 124]\n",
      " [112  81]]\n",
      "\n",
      "Average odds: 232.90825688073394\n",
      "Median odds: 175.0\n",
      "Average odds: 227.15121951219513\n",
      "Median odds: 175.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Using dog data[rolling 9 averages]: \\n\")\n",
    "\n",
    "print(\"Using 9 game standard predictor: \")\n",
    "pred1 = model9.predict(dogs2019[feature9Cols])\n",
    "print('Dog picks:',model9.score(dogs2019[feature9Cols], Ydogs2019))\n",
    "print('Dog picks matrix:\\n',confusion_matrix(Ydogs2019, pred1))\n",
    "print('')\n",
    "\n",
    "print(\"Using 3 game standard predictor: \")\n",
    "pred2 = model3.predict(dogs2019[feature9Cols])\n",
    "print('Dog picks:',model3.score(dogs2019[feature9Cols], Ydogs2019))\n",
    "print('Dog picks matrix:\\n',confusion_matrix(Ydogs2019, pred2))\n",
    "print('')\n",
    "\n",
    "odds = []\n",
    "for i, n in enumerate(pred1):\n",
    "    if n == 1:\n",
    "        odds.append(dogs2019['Odds'][i])\n",
    "\n",
    "print(\"Average odds:\", statistics.mean(odds))\n",
    "print(\"Median odds:\", statistics.median(odds))\n",
    "\n",
    "odds = []\n",
    "for i, n in enumerate(pred2):\n",
    "    if n == 1:\n",
    "        odds.append(dogs2019['Odds'][i])\n",
    "\n",
    "print(\"Average odds:\", statistics.mean(odds))\n",
    "print(\"Median odds:\", statistics.median(odds))\n",
    "\n",
    "\n",
    "print(\"\\nUsing rolling 3 averages: \\n\")\n",
    "\n",
    "print(\"Using 9 game standard predictor: \")\n",
    "pred1 = model9.predict(dogs2019[feature3Cols])\n",
    "print('Dog picks:',model9.score(dogs2019[feature3Cols], Ydogs2019))\n",
    "print('Dog picks matrix:\\n',confusion_matrix(Ydogs2019, pred1))\n",
    "print('')\n",
    "\n",
    "print(\"Using 3 game standard predictor: \")\n",
    "pred2 = model3.predict(dogs2019[feature3Cols])\n",
    "print('Dog picks:',model3.score(dogs2019[feature3Cols], Ydogs2019))\n",
    "print('Dog picks matrix:\\n',confusion_matrix(Ydogs2019, pred2))\n",
    "print('')\n",
    "\n",
    "odds = []\n",
    "for i, n in enumerate(pred1):\n",
    "    if n == 1:\n",
    "        odds.append(dogs2019['Odds'][i])\n",
    "\n",
    "print(\"Average odds:\", statistics.mean(odds))\n",
    "print(\"Median odds:\", statistics.median(odds))\n",
    "\n",
    "odds = []\n",
    "for i, n in enumerate(pred2):\n",
    "    if n == 1:\n",
    "        odds.append(dogs2019['Odds'][i])\n",
    "\n",
    "print(\"Average odds:\", statistics.mean(odds))\n",
    "print(\"Median odds:\", statistics.median(odds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
